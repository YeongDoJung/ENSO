{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import dataprocessing as dp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from Models_3DRFB_Attention_Multilayer_LSTM_Stateful import Model_3D\n",
    "from Parts import *\n",
    "import easydict\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device  0\n",
      "lead phase : [1/2]\n",
      "ensemble phase : [1/10]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Model_3D:\n\tMissing key(s) in state_dict: \"rfb1.branch0.0.conv.weight\", \"rfb1.branch1.0.conv.weight\", \"rfb1.branch1.1.conv.weight\", \"rfb1.branch1.2.conv.weight\", \"rfb1.branch1.3.conv.weight\", \"rfb1.branch2.0.conv.weight\", \"rfb1.branch2.1.conv.weight\", \"rfb1.branch2.2.conv.weight\", \"rfb1.branch2.3.conv.weight\", \"rfb1.branch3.0.conv.weight\", \"rfb1.branch3.1.conv.weight\", \"rfb1.branch3.2.conv.weight\", \"rfb1.branch3.3.conv.weight\", \"rfb1.conv_cat.conv.weight\", \"rfb1.conv_res.conv.weight\", \"rfb2.branch0.0.conv.weight\", \"rfb2.branch1.0.conv.weight\", \"rfb2.branch1.1.conv.weight\", \"rfb2.branch1.2.conv.weight\", \"rfb2.branch1.3.conv.weight\", \"rfb2.branch2.0.conv.weight\", \"rfb2.branch2.1.conv.weight\", \"rfb2.branch2.2.conv.weight\", \"rfb2.branch2.3.conv.weight\", \"rfb2.branch3.0.conv.weight\", \"rfb2.branch3.1.conv.weight\", \"rfb2.branch3.2.conv.weight\", \"rfb2.branch3.3.conv.weight\", \"rfb2.conv_cat.conv.weight\", \"rfb2.conv_res.conv.weight\", \"rfb3.branch0.0.conv.weight\", \"rfb3.branch1.0.conv.weight\", \"rfb3.branch1.1.conv.weight\", \"rfb3.branch1.2.conv.weight\", \"rfb3.branch1.3.conv.weight\", \"rfb3.branch2.0.conv.weight\", \"rfb3.branch2.1.conv.weight\", \"rfb3.branch2.2.conv.weight\", \"rfb3.branch2.3.conv.weight\", \"rfb3.branch3.0.conv.weight\", \"rfb3.branch3.1.conv.weight\", \"rfb3.branch3.2.conv.weight\", \"rfb3.branch3.3.conv.weight\", \"rfb3.conv_cat.conv.weight\", \"rfb3.conv_res.conv.weight\", \"decode_steps.0.weight_ih\", \"decode_steps.0.weight_hh\", \"decode_steps.0.bias_ih\", \"decode_steps.0.bias_hh\", \"decode_steps.1.weight_ih\", \"decode_steps.1.weight_hh\", \"decode_steps.1.bias_ih\", \"decode_steps.1.bias_hh\", \"init_hs.0.weight\", \"init_hs.0.bias\", \"init_hs.1.weight\", \"init_hs.1.bias\", \"init_cs.0.weight\", \"init_cs.0.bias\", \"init_cs.1.weight\", \"init_cs.1.bias\", \"attention.encoder_att.weight\", \"attention.encoder_att.bias\", \"attention.decoder_att.weight\", \"attention.decoder_att.bias\", \"attention.full_att.weight\", \"attention.full_att.bias\", \"f_beta.weight\", \"f_beta.bias\", \"fc.weight\", \"fc.bias\", \"linear1.weight\", \"linear1.bias\", \"linear2.weight\", \"linear2.bias\". \n\tUnexpected key(s) in state_dict: \"module.rfb1.branch0.0.conv.weight\", \"module.rfb1.branch1.0.conv.weight\", \"module.rfb1.branch1.1.conv.weight\", \"module.rfb1.branch1.2.conv.weight\", \"module.rfb1.branch1.3.conv.weight\", \"module.rfb1.branch2.0.conv.weight\", \"module.rfb1.branch2.1.conv.weight\", \"module.rfb1.branch2.2.conv.weight\", \"module.rfb1.branch2.3.conv.weight\", \"module.rfb1.branch3.0.conv.weight\", \"module.rfb1.branch3.1.conv.weight\", \"module.rfb1.branch3.2.conv.weight\", \"module.rfb1.branch3.3.conv.weight\", \"module.rfb1.conv_cat.conv.weight\", \"module.rfb1.conv_res.conv.weight\", \"module.rfb2.branch0.0.conv.weight\", \"module.rfb2.branch1.0.conv.weight\", \"module.rfb2.branch1.1.conv.weight\", \"module.rfb2.branch1.2.conv.weight\", \"module.rfb2.branch1.3.conv.weight\", \"module.rfb2.branch2.0.conv.weight\", \"module.rfb2.branch2.1.conv.weight\", \"module.rfb2.branch2.2.conv.weight\", \"module.rfb2.branch2.3.conv.weight\", \"module.rfb2.branch3.0.conv.weight\", \"module.rfb2.branch3.1.conv.weight\", \"module.rfb2.branch3.2.conv.weight\", \"module.rfb2.branch3.3.conv.weight\", \"module.rfb2.conv_cat.conv.weight\", \"module.rfb2.conv_res.conv.weight\", \"module.rfb3.branch0.0.conv.weight\", \"module.rfb3.branch1.0.conv.weight\", \"module.rfb3.branch1.1.conv.weight\", \"module.rfb3.branch1.2.conv.weight\", \"module.rfb3.branch1.3.conv.weight\", \"module.rfb3.branch2.0.conv.weight\", \"module.rfb3.branch2.1.conv.weight\", \"module.rfb3.branch2.2.conv.weight\", \"module.rfb3.branch2.3.conv.weight\", \"module.rfb3.branch3.0.conv.weight\", \"module.rfb3.branch3.1.conv.weight\", \"module.rfb3.branch3.2.conv.weight\", \"module.rfb3.branch3.3.conv.weight\", \"module.rfb3.conv_cat.conv.weight\", \"module.rfb3.conv_res.conv.weight\", \"module.decode_steps.0.weight_ih\", \"module.decode_steps.0.weight_hh\", \"module.decode_steps.0.bias_ih\", \"module.decode_steps.0.bias_hh\", \"module.decode_steps.1.weight_ih\", \"module.decode_steps.1.weight_hh\", \"module.decode_steps.1.bias_ih\", \"module.decode_steps.1.bias_hh\", \"module.init_hs.0.weight\", \"module.init_hs.0.bias\", \"module.init_hs.1.weight\", \"module.init_hs.1.bias\", \"module.init_cs.0.weight\", \"module.init_cs.0.bias\", \"module.init_cs.1.weight\", \"module.init_cs.1.bias\", \"module.attention.encoder_att.weight\", \"module.attention.encoder_att.bias\", \"module.attention.decoder_att.weight\", \"module.attention.decoder_att.bias\", \"module.attention.full_att.weight\", \"module.attention.full_att.bias\", \"module.f_beta.weight\", \"module.f_beta.bias\", \"module.fc.weight\", \"module.fc.bias\", \"module.linear1.weight\", \"module.linear1.bias\", \"module.linear2.weight\", \"module.linear2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7576/2489090167.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel_3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_answer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/train_{}_{}/train_{}_{}.pth'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlead\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizer_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yd\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1482\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1484\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model_3D:\n\tMissing key(s) in state_dict: \"rfb1.branch0.0.conv.weight\", \"rfb1.branch1.0.conv.weight\", \"rfb1.branch1.1.conv.weight\", \"rfb1.branch1.2.conv.weight\", \"rfb1.branch1.3.conv.weight\", \"rfb1.branch2.0.conv.weight\", \"rfb1.branch2.1.conv.weight\", \"rfb1.branch2.2.conv.weight\", \"rfb1.branch2.3.conv.weight\", \"rfb1.branch3.0.conv.weight\", \"rfb1.branch3.1.conv.weight\", \"rfb1.branch3.2.conv.weight\", \"rfb1.branch3.3.conv.weight\", \"rfb1.conv_cat.conv.weight\", \"rfb1.conv_res.conv.weight\", \"rfb2.branch0.0.conv.weight\", \"rfb2.branch1.0.conv.weight\", \"rfb2.branch1.1.conv.weight\", \"rfb2.branch1.2.conv.weight\", \"rfb2.branch1.3.conv.weight\", \"rfb2.branch2.0.conv.weight\", \"rfb2.branch2.1.conv.weight\", \"rfb2.branch2.2.conv.weight\", \"rfb2.branch2.3.conv.weight\", \"rfb2.branch3.0.conv.weight\", \"rfb2.branch3.1.conv.weight\", \"rfb2.branch3.2.conv.weight\", \"rfb2.branch3.3.conv.weight\", \"rfb2.conv_cat.conv.weight\", \"rfb2.conv_res.conv.weight\", \"rfb3.branch0.0.conv.weight\", \"rfb3.branch1.0.conv.weight\", \"rfb3.branch1.1.conv.weight\", \"rfb3.branch1.2.conv.weight\", \"rfb3.branch1.3.conv.weight\", \"rfb3.branch2.0.conv.weight\", \"rfb3.branch2.1.conv.weight\", \"rfb3.branch2.2.conv.weight\", \"rfb3.branch2.3.conv.weight\", \"rfb3.branch3.0.conv.weight\", \"rfb3.branch3.1.conv.weight\", \"rfb3.branch3.2.conv.weight\", \"rfb3.branch3.3.conv.weight\", \"rfb3.conv_cat.conv.weight\", \"rfb3.conv_res.conv.weight\", \"decode_steps.0.weight_ih\", \"decode_steps.0.weight_hh\", \"decode_steps.0.bias_ih\", \"decode_steps.0.bias_hh\", \"decode_steps.1.weight_ih\", \"decode_steps.1.weight_hh\", \"decode_steps.1.bias_ih\", \"decode_steps.1.bias_hh\", \"init_hs.0.weight\", \"init_hs.0.bias\", \"init_hs.1.weight\", \"init_hs.1.bias\", \"init_cs.0.weight\", \"init_cs.0.bias\", \"init_cs.1.weight\", \"init_cs.1.bias\", \"attention.encoder_att.weight\", \"attention.encoder_att.bias\", \"attention.decoder_att.weight\", \"attention.decoder_att.bias\", \"attention.full_att.weight\", \"attention.full_att.bias\", \"f_beta.weight\", \"f_beta.bias\", \"fc.weight\", \"fc.bias\", \"linear1.weight\", \"linear1.bias\", \"linear2.weight\", \"linear2.bias\". \n\tUnexpected key(s) in state_dict: \"module.rfb1.branch0.0.conv.weight\", \"module.rfb1.branch1.0.conv.weight\", \"module.rfb1.branch1.1.conv.weight\", \"module.rfb1.branch1.2.conv.weight\", \"module.rfb1.branch1.3.conv.weight\", \"module.rfb1.branch2.0.conv.weight\", \"module.rfb1.branch2.1.conv.weight\", \"module.rfb1.branch2.2.conv.weight\", \"module.rfb1.branch2.3.conv.weight\", \"module.rfb1.branch3.0.conv.weight\", \"module.rfb1.branch3.1.conv.weight\", \"module.rfb1.branch3.2.conv.weight\", \"module.rfb1.branch3.3.conv.weight\", \"module.rfb1.conv_cat.conv.weight\", \"module.rfb1.conv_res.conv.weight\", \"module.rfb2.branch0.0.conv.weight\", \"module.rfb2.branch1.0.conv.weight\", \"module.rfb2.branch1.1.conv.weight\", \"module.rfb2.branch1.2.conv.weight\", \"module.rfb2.branch1.3.conv.weight\", \"module.rfb2.branch2.0.conv.weight\", \"module.rfb2.branch2.1.conv.weight\", \"module.rfb2.branch2.2.conv.weight\", \"module.rfb2.branch2.3.conv.weight\", \"module.rfb2.branch3.0.conv.weight\", \"module.rfb2.branch3.1.conv.weight\", \"module.rfb2.branch3.2.conv.weight\", \"module.rfb2.branch3.3.conv.weight\", \"module.rfb2.conv_cat.conv.weight\", \"module.rfb2.conv_res.conv.weight\", \"module.rfb3.branch0.0.conv.weight\", \"module.rfb3.branch1.0.conv.weight\", \"module.rfb3.branch1.1.conv.weight\", \"module.rfb3.branch1.2.conv.weight\", \"module.rfb3.branch1.3.conv.weight\", \"module.rfb3.branch2.0.conv.weight\", \"module.rfb3.branch2.1.conv.weight\", \"module.rfb3.branch2.2.conv.weight\", \"module.rfb3.branch2.3.conv.weight\", \"module.rfb3.branch3.0.conv.weight\", \"module.rfb3.branch3.1.conv.weight\", \"module.rfb3.branch3.2.conv.weight\", \"module.rfb3.branch3.3.conv.weight\", \"module.rfb3.conv_cat.conv.weight\", \"module.rfb3.conv_res.conv.weight\", \"module.decode_steps.0.weight_ih\", \"module.decode_steps.0.weight_hh\", \"module.decode_steps.0.bias_ih\", \"module.decode_steps.0.bias_hh\", \"module.decode_steps.1.weight_ih\", \"module.decode_steps.1.weight_hh\", \"module.decode_steps.1.bias_ih\", \"module.decode_steps.1.bias_hh\", \"module.init_hs.0.weight\", \"module.init_hs.0.bias\", \"module.init_hs.1.weight\", \"module.init_hs.1.bias\", \"module.init_cs.0.weight\", \"module.init_cs.0.bias\", \"module.init_cs.1.weight\", \"module.init_cs.1.bias\", \"module.attention.encoder_att.weight\", \"module.attention.encoder_att.bias\", \"module.attention.decoder_att.weight\", \"module.attention.decoder_att.bias\", \"module.attention.full_att.weight\", \"module.attention.full_att.bias\", \"module.f_beta.weight\", \"module.f_beta.bias\", \"module.fc.weight\", \"module.fc.bias\", \"module.linear1.weight\", \"module.linear1.bias\", \"module.linear2.weight\", \"module.linear2.bias\". "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Random seed \n",
    "    # torch.backends.cudnn.deterministic = True \n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # Arguments\n",
    "    args = easydict.EasyDict({\n",
    "        \"startLead\": 1,\n",
    "        \"endLead\": 2,\n",
    "        \"gpu\": 0,\n",
    "        \"input\": 3\n",
    "    })\n",
    "\n",
    "    # Directories\n",
    "    # Dataset for pretrain\n",
    "    Folder = \"d:/code/ENSO/ENSO_Ham/local/pretrain_3DRFB_Attention_Multilayer_LSTM_Stateful_3/\"\n",
    "    dataFolder = \"d:/code/ENSO/ENSO_Ham/local/Dataset/Ham\" #\"./\"\"./\"\n",
    "\n",
    "#     # Dataset for finetuning\n",
    "#     Folder = \"./finetuning_3DRFB_Attention_3\"\n",
    "#     dataFolder = \"./\"\n",
    "    \n",
    "    SSTFile_val = dataFolder+'/godas.input.1980_2017.nc'\n",
    "    SSTFile_val_label = dataFolder+'/godas.label.1980_2017.nc'\n",
    "\n",
    "    device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(device) # change allocation of current GPU\n",
    "    print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "    # Set Hyper-parameters\n",
    "    regularizer_rate = 0.00001  #L2 regularization\n",
    "    numEpoch =  40              # No. Epoch\n",
    "    learning_rate = 0.0001      # Initial Learning Rate\n",
    "    n_cycles = 4                # No. cycles in Cosine Annealing\n",
    "    epochs_per_cycle = math.floor(numEpoch / n_cycles)  # No. epochs for each cycle\n",
    "\n",
    "    dr = 0.0                   # Dropout rate for Bayesian learning\n",
    "    tau = 1.0                   # Weight for the batch size in regularization weight calculation (Bayesian learning)\n",
    "    lengthscale = 1e-2          # Default regularization weight (L2)\n",
    "    noF = 16                    # Initial No. filters\n",
    "    num_layer = 256             # Feature size of 1st fully-connected layer\n",
    "    num_answer = 2              # No. answers(3=3.4/ep/cp)\n",
    "\n",
    "    ENS_Start = 0\n",
    "    ENS = 10\n",
    "    # loop - 1 time only\n",
    "    for lead in range(args.startLead, args.endLead) :\n",
    "        print('lead phase : [{}/{}]'.format(lead, args.endLead))\n",
    "\n",
    "        # Dataset for training\n",
    "        valset = datasets_general_3D_alllead(SSTFile_val, SSTFile_val_label, lead, sstName='sst', hcName='t300', labelName='pr', noise = False)\n",
    "        batch_size = len(valset) // 1                             # batch size\n",
    "        reg = lengthscale**2 * (1 - dr) / (2. * batch_size * tau) # L2 regularization weight for Bayesian learning\n",
    "        testloader = DataLoader(valset, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "        test_step = len(testloader)\n",
    "        assemble_real_type = np.zeros((len(valset)))\n",
    "        assemble_pred_type = np.zeros((len(valset)))\n",
    "        assemble_pred_prop = np.zeros((len(valset), 12))\n",
    "\n",
    "        assemble_real_nino = np.zeros((len(valset), 23))\n",
    "        assemble_pred_nino = np.zeros((len(valset), 23))\n",
    "        for ens in range(ENS_Start, ENS) :\n",
    "            print('ensemble phase : [{}/{}]'.format(ens+1, ENS))\n",
    "\n",
    "            model = Model_3D(2, noF, num_layer, num_answer, dr, args.input).to(device)\n",
    "            model.load_state_dict(torch.load('{}/train_{}_{}/train_{}_{}.pth'.format(Folder, lead, ens, lead, ens)))\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=regularizer_rate, betas=(0.9, 0.999))\n",
    "            model.eval()\n",
    "            \n",
    "            bayesianIter = 1\n",
    "\n",
    "            with torch.no_grad() :\n",
    "                for i, (batch, ansnino, anstype) in enumerate(testloader):\n",
    "                    batch = Variable(batch.float().cuda())\n",
    "                    ansnino = Variable(ansnino.float().cuda())\n",
    "                    anstype = Variable(anstype.float().cuda())\n",
    "                    idx = batch_size*i\n",
    "                    uncertaintyarry_nino = np.zeros((bayesianIter, batch_size, 23))\n",
    "                    uncertaintyarry_type = np.zeros((bayesianIter, batch_size, 12))\n",
    "                    for b in range(int(bayesianIter)):\n",
    "                        output = model(batch) # inference\n",
    "                        prednino = np.squeeze(output[0], axis=2)\n",
    "                        uncertaintyarry_nino[b, :, :] = prednino.cpu()\n",
    "                        uncertaintyarry_type[b, :, :] = torch.nn.functional.softmax(output[1], dim=1).cpu()\n",
    "\n",
    "                    if ens == 0:\n",
    "                        assemble_real_nino[idx:idx+batch_size, :] = ansnino.cpu().numpy()\n",
    "                        anstype = torch.argmax(anstype, dim=1).cpu().numpy()\n",
    "                        assemble_real_type[idx:idx+batch_size] = anstype\n",
    "\n",
    "                    assemble_pred_nino[idx:idx+batch_size, :] += np.mean(uncertaintyarry_nino, axis=0)\n",
    "                    predMean = np.mean(uncertaintyarry_type, axis = 0)\n",
    "                    # assemble_pred_type[idx:idx+batch_size] += np.argmax(predMean, axis = 1)\n",
    "                    assemble_pred_prop[idx:idx+batch_size, :] += predMean\n",
    "\n",
    "                    del batch\n",
    "                    del ansnino\n",
    "                    del anstype\n",
    "        \n",
    "        # End of ensemble\n",
    "        assemble_pred_nino /= ENS\n",
    "        assemble_pred_prop /= ENS\n",
    "        print(assemble_pred_nino)\n",
    "        assemble_pred_type = np.argmax(assemble_pred_prop, axis = 1)\n",
    "\n",
    "        corr = np.zeros(23)\n",
    "        for i in range(23):\n",
    "            corr[i] = dp.CorrelationSkill(assemble_real_nino[:, i], assemble_pred_nino[:, i])\n",
    "            print(corr[i])\n",
    "            print('Save prediction: lead = {}'.format(i) )\n",
    "            inputTimeSeq = assemble_real_nino.shape[0]\n",
    "            dwidth = 800\n",
    "            dpi = 90\n",
    "            dheight = 180\n",
    "            plt.figure(figsize=(dwidth/dpi, dheight/dpi))\n",
    "            timeValues = np.arange(0, inputTimeSeq)\n",
    "            plt.plot(timeValues, assemble_real_nino[:, i], marker='', color='blue', linewidth=1, label=\"Measurement\")\n",
    "            plt.plot(timeValues, assemble_pred_nino[:, i], marker='', color='red', linewidth=1, linestyle='dashed', label=\"Prediction\")\n",
    "            plt.savefig(Folder + \"/NinoPred_\" + str(i).zfill(6) + \".png\", orientation='landscape', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        \n",
    "        np.savetxt(Folder + '/correlation.csv',corr,delimiter=\",\")\n",
    "        \n",
    "        print('Save classification: lead = {}'.format(i) )\n",
    "        plt.figure(figsize=(dwidth/dpi, dheight/dpi))\n",
    "        timeValues = np.arange(0, inputTimeSeq)\n",
    "        plt.plot(timeValues, assemble_real_type, marker='', color='blue', linewidth=1, label=\"Measurement\")\n",
    "        plt.plot(timeValues, assemble_pred_type, marker='', color='red', linewidth=1, linestyle='dashed', label=\"Prediction\")\n",
    "        plt.savefig(Folder + \"/Month_Classification\" + \".png\", orientation='landscape', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        accuracy = np.zeros(1)\n",
    "        accuracy[0] = accuracy_score(assemble_real_type, assemble_pred_type)\n",
    "        print('Accuracy = {}'.format(accuracy))\n",
    "        np.savetxt(Folder + '/accuracy.csv',accuracy,delimiter=\",\")\n",
    "\n",
    "\n",
    "        # print(assemble_pred_nino)\n",
    "        np.save(\"{}/lead_{}_assemble_real_nino\".format(Folder, lead), assemble_real_nino) # 길이가 valset인 것이 ensemble 갯수 만큼 들어있음\n",
    "        np.save(\"{}/lead_{}_assemble_real_type\".format(Folder, lead), assemble_real_type)\n",
    "        np.save(\"{}/lead_{}_assemble_pred_nino\".format(Folder, lead), assemble_pred_nino)\n",
    "        np.save(\"{}/lead_{}_assemble_pred_type\".format(Folder, lead), assemble_pred_type)\n",
    "        np.save(\"{}/lead_{}_assemble_pred_prop\".format(Folder, lead), assemble_pred_prop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d67d0f6f2aed9fe819e3c7c75ced2ce66c55c94683d7ae02f20dff5595116596"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('yd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "7bd0759b810153da84264fee8ab3444adda3a1f3810089f2abacf00e6e0ac8ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

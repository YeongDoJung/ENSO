{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from lstf.model.mdl import RFB_Transformer\n",
    "from lstf.datasets.basicdatasets import basicdataset\n",
    "from Parts import *\n",
    "import easydict\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\dudeh\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Random seed \n",
    "    # torch.backends.cudnn.deterministic = True \n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # Arguments\n",
    "    args = easydict.EasyDict({\n",
    "        \"gpu\": 1,\n",
    "    })\n",
    "\n",
    "    # Directories\n",
    "    # Dataset for pretrain\n",
    "    Folder = \"./local/3DRFB_Transformer/\"\n",
    "    folders = sorted(os.listdir(Folder))\n",
    "    dataFolder = \"./local/Dataset/Ham\" #\"./\"\"./\"\n",
    "\n",
    "    SSTFile_val = dataFolder+'/godas.input.1980_2017.nc'\n",
    "    SSTFile_val_label = dataFolder+'/godas.label.1980_2017.nc'\n",
    "\n",
    "    device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(device) # change allocation of current GPU\n",
    "    print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "    # Set Hyper-parameters\n",
    "    regularizer_rate = 0.00001  #L2 regularization\n",
    "    numEpoch =  100              # No. Epoch\n",
    "    learning_rate = 0.0001      # Initial Learning Rate\n",
    "    n_cycles = 4                # No. cycles in Cosine Annealing\n",
    "    epochs_per_cycle = math.floor(numEpoch / n_cycles)  # No. epochs for each cycle\n",
    "\n",
    "    dr = 0.0                   # Dropout rate for Bayesian learning\n",
    "    tau = 1.0                   # Weight for the batch size in regularization weight calculation (Bayesian learning)\n",
    "    lengthscale = 1e-2          # Default regularization weight (L2)\n",
    "    noF = 16                    # Initial No. filters\n",
    "    num_layer = 256             # Feature size of 1st fully-connected layer\n",
    "    num_answer = 2              # No. answers(3=3.4/ep/cp)\n",
    "\n",
    "    # Dataset for training\n",
    "    valset = basicdataset(SSTFile_val, SSTFile_val_label, sstName='sst', hcName='t300', labelName='pr')\n",
    "    batch_size = len(valset) // 1                             # batch size\n",
    "    reg = lengthscale**2 * (1 - dr) / (2. * batch_size * tau) # L2 regularization weight for Bayesian learning\n",
    "    testloader = DataLoader(valset, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "    test_step = len(testloader)\n",
    "\n",
    "    assemble_real_nino = np.zeros((len(valset), 23))\n",
    "    assemble_pred_nino = np.zeros((len(valset), 23))\n",
    "\n",
    "    model = RFB_Transformer(in_channel=2, out_channel=16).to(device)\n",
    "    model.load_state_dict(torch.load(f'{Folder}/eval_6/eval_6.pth'))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=regularizer_rate, betas=(0.9, 0.999))\n",
    "    model.eval()\n",
    "    \n",
    "    bayesianIter = 1\n",
    "\n",
    "    with torch.no_grad() :\n",
    "        for i, (batch, ansnino) in enumerate(testloader):\n",
    "            batch = torch.tensor(batch, dtype=torch.float32).to(device=device)\n",
    "            ansnino = torch.tensor(ansnino, dtype=torch.float32).to(device=device)\n",
    "            ansnino = 1 / (1 + torch.exp(-1*ansnino)) - 0.5\n",
    "            idx = batch.shape[0]*i\n",
    "            uncertaintyarry_nino = np.zeros((bayesianIter, batch_size, 23))\n",
    "            for b in range(int(bayesianIter)):\n",
    "                output = model(batch) # inference\n",
    "                output = 1 / (1 + torch.exp(-1*output))\n",
    "                prednino = output.detach().cpu().numpy()\n",
    "                uncertaintyarry_nino[b, :, :] = prednino\n",
    "\n",
    "            assemble_real_nino[idx:idx+batch_size, :] = ansnino.cpu().numpy()\n",
    "\n",
    "            assemble_pred_nino[idx:idx+batch_size, :] += np.mean(uncertaintyarry_nino, axis=0)\n",
    "\n",
    "            del batch\n",
    "            del ansnino\n",
    "    \n",
    "    corr = np.zeros(23)\n",
    "    for i in range(23):\n",
    "        corr[i] = dp.CorrelationSkill(assemble_real_nino[:, i], assemble_pred_nino[:, i])\n",
    "        print(corr[i])\n",
    "        print('Save prediction: lead = {}'.format(i) )\n",
    "        inputTimeSeq = assemble_real_nino.shape[0]\n",
    "        dwidth = 800\n",
    "        dpi = 90\n",
    "        dheight = 180\n",
    "        plt.figure(figsize=(dwidth/dpi, dheight/dpi))\n",
    "        timeValues = np.arange(0, inputTimeSeq)\n",
    "        # plt.plot(timeValues, assemble_real_nino[:, i], marker='', color='blue', linewidth=1, label=\"Measurement\")\n",
    "        # plt.plot(timeValues, assemble_pred_nino[:, i], marker='', color='red', linewidth=1, linestyle='dashed', label=\"Prediction\")\n",
    "        plt.savefig(Folder + \"/NinoPred_\" + str(i).zfill(6) + \".png\", orientation='landscape', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    np.savetxt(f'{Folder}/eval_6/correlation.csv',corr,delimiter=\",\")\n",
    "\n",
    "    # print(assemble_pred_nino)\n",
    "    np.save(f\"{Folder}/eval_6/lead_assemble_real_nino\", assemble_real_nino) # 길이가 valset인 것이 ensemble 갯수 만큼 들어있음\n",
    "    np.save(f\"{Folder}/eval_6/lead_assemble_pred_nino\", assemble_pred_nino)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d67d0f6f2aed9fe819e3c7c75ced2ce66c55c94683d7ae02f20dff5595116596"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('yd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "7bd0759b810153da84264fee8ab3444adda3a1f3810089f2abacf00e6e0ac8ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
